{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Dataframes memory\n",
    "    In this project we are going to work with financial lending data from \"Lending Club\", a marketplace for personal loans that matches borrowers with investors. Our goal here is to optimize the dataframe and the processing in chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 99    #We set the max as 99, so that we could see all the columns of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
      "0  1077501  1296599.0     5000.0       5000.0           4975.0   36 months   \n",
      "1  1077430  1314167.0     2500.0       2500.0           2500.0   60 months   \n",
      "2  1077175  1313524.0     2400.0       2400.0           2400.0   36 months   \n",
      "3  1076863  1277178.0    10000.0      10000.0          10000.0   36 months   \n",
      "4  1075358  1311748.0     3000.0       3000.0           3000.0   60 months   \n",
      "\n",
      "  int_rate  installment grade sub_grade                 emp_title emp_length  \\\n",
      "0   10.65%       162.87     B        B2                       NaN  10+ years   \n",
      "1   15.27%        59.83     C        C4                     Ryder   < 1 year   \n",
      "2   15.96%        84.33     C        C5                       NaN  10+ years   \n",
      "3   13.49%       339.31     C        C1       AIR RESOURCES BOARD  10+ years   \n",
      "4   12.69%        67.79     B        B5  University Medical Group     1 year   \n",
      "\n",
      "  home_ownership  annual_inc verification_status   issue_d  loan_status  \\\n",
      "0           RENT     24000.0            Verified  Dec-2011   Fully Paid   \n",
      "1           RENT     30000.0     Source Verified  Dec-2011  Charged Off   \n",
      "2           RENT     12252.0        Not Verified  Dec-2011   Fully Paid   \n",
      "3           RENT     49200.0     Source Verified  Dec-2011   Fully Paid   \n",
      "4           RENT     80000.0     Source Verified  Dec-2011      Current   \n",
      "\n",
      "  pymnt_plan         purpose                 title zip_code addr_state    dti  \\\n",
      "0          n     credit_card              Computer    860xx         AZ  27.65   \n",
      "1          n             car                  bike    309xx         GA   1.00   \n",
      "2          n  small_business  real estate business    606xx         IL   8.72   \n",
      "3          n           other              personel    917xx         CA  20.00   \n",
      "4          n           other              Personal    972xx         OR  17.94   \n",
      "\n",
      "   delinq_2yrs earliest_cr_line  inq_last_6mths  open_acc  pub_rec  revol_bal  \\\n",
      "0          0.0         Jan-1985             1.0       3.0      0.0    13648.0   \n",
      "1          0.0         Apr-1999             5.0       3.0      0.0     1687.0   \n",
      "2          0.0         Nov-2001             2.0       2.0      0.0     2956.0   \n",
      "3          0.0         Feb-1996             1.0      10.0      0.0     5598.0   \n",
      "4          0.0         Jan-1996             0.0      15.0      0.0    27783.0   \n",
      "\n",
      "  revol_util  total_acc initial_list_status  out_prncp  out_prncp_inv  \\\n",
      "0      83.7%        9.0                   f       0.00           0.00   \n",
      "1       9.4%        4.0                   f       0.00           0.00   \n",
      "2      98.5%       10.0                   f       0.00           0.00   \n",
      "3        21%       37.0                   f       0.00           0.00   \n",
      "4      53.9%       38.0                   f     461.73         461.73   \n",
      "\n",
      "    total_pymnt  total_pymnt_inv  total_rec_prncp  total_rec_int  \\\n",
      "0   5863.155187          5833.84          5000.00         863.16   \n",
      "1   1008.710000          1008.71           456.46         435.17   \n",
      "2   3005.666844          3005.67          2400.00         605.67   \n",
      "3  12231.890000         12231.89         10000.00        2214.92   \n",
      "4   3581.120000          3581.12          2538.27        1042.85   \n",
      "\n",
      "   total_rec_late_fee  recoveries  collection_recovery_fee last_pymnt_d  \\\n",
      "0                0.00        0.00                     0.00     Jan-2015   \n",
      "1                0.00      117.08                     1.11     Apr-2013   \n",
      "2                0.00        0.00                     0.00     Jun-2014   \n",
      "3               16.97        0.00                     0.00     Jan-2015   \n",
      "4                0.00        0.00                     0.00     Jun-2016   \n",
      "\n",
      "   last_pymnt_amnt last_credit_pull_d  collections_12_mths_ex_med  \\\n",
      "0           171.62           Jun-2016                         0.0   \n",
      "1           119.66           Sep-2013                         0.0   \n",
      "2           649.91           Jun-2016                         0.0   \n",
      "3           357.48           Apr-2016                         0.0   \n",
      "4            67.79           Jun-2016                         0.0   \n",
      "\n",
      "   policy_code application_type  acc_now_delinq  chargeoff_within_12_mths  \\\n",
      "0          1.0       INDIVIDUAL             0.0                       0.0   \n",
      "1          1.0       INDIVIDUAL             0.0                       0.0   \n",
      "2          1.0       INDIVIDUAL             0.0                       0.0   \n",
      "3          1.0       INDIVIDUAL             0.0                       0.0   \n",
      "4          1.0       INDIVIDUAL             0.0                       0.0   \n",
      "\n",
      "   delinq_amnt  pub_rec_bankruptcies  tax_liens  \n",
      "0          0.0                   0.0        0.0  \n",
      "1          0.0                   0.0        0.0  \n",
      "2          0.0                   0.0        0.0  \n",
      "3          0.0                   0.0        0.0  \n",
      "4          0.0                   0.0        0.0  \n"
     ]
    }
   ],
   "source": [
    "#Let's print the first 5 lines from loans_2007.csv to look for any data quality issues\n",
    "\n",
    "file_head=pd.read_csv(\"loans_2007.csv\", nrows=5)  #We use nrows since we don't want to read the entire file as it takes time\n",
    "\n",
    "print(file_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 52 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   id                          1000 non-null   int64  \n",
      " 1   member_id                   1000 non-null   float64\n",
      " 2   loan_amnt                   1000 non-null   float64\n",
      " 3   funded_amnt                 1000 non-null   float64\n",
      " 4   funded_amnt_inv             1000 non-null   float64\n",
      " 5   term                        1000 non-null   object \n",
      " 6   int_rate                    1000 non-null   object \n",
      " 7   installment                 1000 non-null   float64\n",
      " 8   grade                       1000 non-null   object \n",
      " 9   sub_grade                   1000 non-null   object \n",
      " 10  emp_title                   949 non-null    object \n",
      " 11  emp_length                  983 non-null    object \n",
      " 12  home_ownership              1000 non-null   object \n",
      " 13  annual_inc                  1000 non-null   float64\n",
      " 14  verification_status         1000 non-null   object \n",
      " 15  issue_d                     1000 non-null   object \n",
      " 16  loan_status                 1000 non-null   object \n",
      " 17  pymnt_plan                  1000 non-null   object \n",
      " 18  purpose                     1000 non-null   object \n",
      " 19  title                       1000 non-null   object \n",
      " 20  zip_code                    1000 non-null   object \n",
      " 21  addr_state                  1000 non-null   object \n",
      " 22  dti                         1000 non-null   float64\n",
      " 23  delinq_2yrs                 1000 non-null   float64\n",
      " 24  earliest_cr_line            1000 non-null   object \n",
      " 25  inq_last_6mths              1000 non-null   float64\n",
      " 26  open_acc                    1000 non-null   float64\n",
      " 27  pub_rec                     1000 non-null   float64\n",
      " 28  revol_bal                   1000 non-null   float64\n",
      " 29  revol_util                  1000 non-null   object \n",
      " 30  total_acc                   1000 non-null   float64\n",
      " 31  initial_list_status         1000 non-null   object \n",
      " 32  out_prncp                   1000 non-null   float64\n",
      " 33  out_prncp_inv               1000 non-null   float64\n",
      " 34  total_pymnt                 1000 non-null   float64\n",
      " 35  total_pymnt_inv             1000 non-null   float64\n",
      " 36  total_rec_prncp             1000 non-null   float64\n",
      " 37  total_rec_int               1000 non-null   float64\n",
      " 38  total_rec_late_fee          1000 non-null   float64\n",
      " 39  recoveries                  1000 non-null   float64\n",
      " 40  collection_recovery_fee     1000 non-null   float64\n",
      " 41  last_pymnt_d                999 non-null    object \n",
      " 42  last_pymnt_amnt             1000 non-null   float64\n",
      " 43  last_credit_pull_d          1000 non-null   object \n",
      " 44  collections_12_mths_ex_med  1000 non-null   float64\n",
      " 45  policy_code                 1000 non-null   float64\n",
      " 46  application_type            1000 non-null   object \n",
      " 47  acc_now_delinq              1000 non-null   float64\n",
      " 48  chargeoff_within_12_mths    1000 non-null   float64\n",
      " 49  delinq_amnt                 1000 non-null   float64\n",
      " 50  pub_rec_bankruptcies        1000 non-null   float64\n",
      " 51  tax_liens                   1000 non-null   float64\n",
      "dtypes: float64(30), int64(1), object(21)\n",
      "memory usage: 1.5 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Calculating the chunk amount to keep the chunk's memory between 5 MB.\n",
    "\n",
    "#First let's try with 1000 rows\n",
    "\n",
    "first_1000 = pd.read_csv(\"loans_2007.csv\", nrows=1000)\n",
    "\n",
    "print(first_1000.info(memory_usage='deep'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having 1000 rows, shows memory usage of 1.5 MB. Therefore we can try to check for 3000 rows, to be between the 5 MB target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 52 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   id                          3000 non-null   int64  \n",
      " 1   member_id                   3000 non-null   float64\n",
      " 2   loan_amnt                   3000 non-null   float64\n",
      " 3   funded_amnt                 3000 non-null   float64\n",
      " 4   funded_amnt_inv             3000 non-null   float64\n",
      " 5   term                        3000 non-null   object \n",
      " 6   int_rate                    3000 non-null   object \n",
      " 7   installment                 3000 non-null   float64\n",
      " 8   grade                       3000 non-null   object \n",
      " 9   sub_grade                   3000 non-null   object \n",
      " 10  emp_title                   2829 non-null   object \n",
      " 11  emp_length                  2917 non-null   object \n",
      " 12  home_ownership              3000 non-null   object \n",
      " 13  annual_inc                  3000 non-null   float64\n",
      " 14  verification_status         3000 non-null   object \n",
      " 15  issue_d                     3000 non-null   object \n",
      " 16  loan_status                 3000 non-null   object \n",
      " 17  pymnt_plan                  3000 non-null   object \n",
      " 18  purpose                     3000 non-null   object \n",
      " 19  title                       3000 non-null   object \n",
      " 20  zip_code                    3000 non-null   object \n",
      " 21  addr_state                  3000 non-null   object \n",
      " 22  dti                         3000 non-null   float64\n",
      " 23  delinq_2yrs                 3000 non-null   float64\n",
      " 24  earliest_cr_line            3000 non-null   object \n",
      " 25  inq_last_6mths              3000 non-null   float64\n",
      " 26  open_acc                    3000 non-null   float64\n",
      " 27  pub_rec                     3000 non-null   float64\n",
      " 28  revol_bal                   3000 non-null   float64\n",
      " 29  revol_util                  3000 non-null   object \n",
      " 30  total_acc                   3000 non-null   float64\n",
      " 31  initial_list_status         3000 non-null   object \n",
      " 32  out_prncp                   3000 non-null   float64\n",
      " 33  out_prncp_inv               3000 non-null   float64\n",
      " 34  total_pymnt                 3000 non-null   float64\n",
      " 35  total_pymnt_inv             3000 non-null   float64\n",
      " 36  total_rec_prncp             3000 non-null   float64\n",
      " 37  total_rec_int               3000 non-null   float64\n",
      " 38  total_rec_late_fee          3000 non-null   float64\n",
      " 39  recoveries                  3000 non-null   float64\n",
      " 40  collection_recovery_fee     3000 non-null   float64\n",
      " 41  last_pymnt_d                2998 non-null   object \n",
      " 42  last_pymnt_amnt             3000 non-null   float64\n",
      " 43  last_credit_pull_d          3000 non-null   object \n",
      " 44  collections_12_mths_ex_med  3000 non-null   float64\n",
      " 45  policy_code                 3000 non-null   float64\n",
      " 46  application_type            3000 non-null   object \n",
      " 47  acc_now_delinq              3000 non-null   float64\n",
      " 48  chargeoff_within_12_mths    3000 non-null   float64\n",
      " 49  delinq_amnt                 3000 non-null   float64\n",
      " 50  pub_rec_bankruptcies        3000 non-null   float64\n",
      " 51  tax_liens                   3000 non-null   float64\n",
      "dtypes: float64(30), int64(1), object(21)\n",
      "memory usage: 4.6 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "first_3000 = pd.read_csv(\"loans_2007.csv\", nrows=3000)\n",
    "\n",
    "print(first_3000.info(memory_usage='deep'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we expected, having 3000 rows shows only 4.6 MB which makes it as the perfect chunk size. \n",
    "Now, Let's check if the same memory usage consists across all other chunks and also count the total memory, no of rows the file has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.580394744873047\n",
      "4.576141357421875\n",
      "4.577898979187012\n",
      "4.579251289367676\n",
      "4.575444221496582\n",
      "4.577326774597168\n",
      "4.575918197631836\n",
      "4.578287124633789\n",
      "4.576413154602051\n",
      "4.57646369934082\n",
      "4.589176177978516\n",
      "4.588043212890625\n",
      "4.594850540161133\n",
      "4.828314781188965\n",
      "0.868586540222168\n",
      "\n",
      " 42538\n"
     ]
    }
   ],
   "source": [
    "chunk_iter=pd.read_csv(\"loans_2007.csv\", chunksize=3000)\n",
    "\n",
    "total_row = 0\n",
    "\n",
    "for chunk in chunk_iter:\n",
    "    total_row+=len(chunk)\n",
    "    print(chunk.memory_usage(deep=True).sum()/2**20)\n",
    "    \n",
    "print(\"\\n\", total_row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file loans_2007.csv has 42538 rows and 65.24 MB in total. We have also verified if the chunk's memory exceed more than 5 MB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many column have a numeric type? \n",
    "\n",
    "Let's find out how many columns have numeric data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 30, 30]\n",
      "[21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 22]\n"
     ]
    }
   ],
   "source": [
    "chunk_iter=pd.read_csv(\"loans_2007.csv\", chunksize=3000)\n",
    "\n",
    "numeric_col=[]\n",
    "string_col=[]\n",
    "\n",
    "for chunk in chunk_iter:\n",
    "    numeric_chunk=chunk.select_dtypes(include=['int64','float64'])   #Will output the complete dataframe that has only numeric dtype\n",
    "    string_chunk=chunk.select_dtypes(include=['object'])       #Will output the complete dataframe that has only object dtype\n",
    "    \n",
    "    numeric_col.append(numeric_chunk.shape[1])    #this will append the no of col of each chunk into numeric_col\n",
    "    string_col.append(string_chunk.shape[1])      #this will append the no of col of each chunk into string_col\n",
    "\n",
    "#now the we have the list of numeric_col numbers, let's sum the numbers to get the total.\n",
    "print(numeric_col)\n",
    "print(string_col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, during the last 2 chunks of both numeric and object column, there is a discripency in the numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " all_colums: ['term', 'int_rate', 'grade', 'sub_grade', 'emp_title', 'emp_length', 'home_ownership', 'verification_status', 'issue_d', 'loan_status', 'pymnt_plan', 'purpose', 'title', 'zip_code', 'addr_state', 'earliest_cr_line', 'revol_util', 'initial_list_status', 'last_pymnt_d', 'last_credit_pull_d', 'application_type']\n",
      "\n",
      " chunk_object_columns: ['id', 'term', 'int_rate', 'grade', 'sub_grade', 'emp_title', 'emp_length', 'home_ownership', 'verification_status', 'issue_d', 'loan_status', 'pymnt_plan', 'purpose', 'title', 'zip_code', 'addr_state', 'earliest_cr_line', 'revol_util', 'initial_list_status', 'last_pymnt_d', 'last_credit_pull_d', 'application_type']\n",
      "\n",
      " all_colums: ['term', 'int_rate', 'grade', 'sub_grade', 'emp_title', 'emp_length', 'home_ownership', 'verification_status', 'issue_d', 'loan_status', 'pymnt_plan', 'purpose', 'title', 'zip_code', 'addr_state', 'earliest_cr_line', 'revol_util', 'initial_list_status', 'last_pymnt_d', 'last_credit_pull_d', 'application_type']\n",
      "\n",
      " chunk_object_columns: ['id', 'term', 'int_rate', 'grade', 'sub_grade', 'emp_title', 'emp_length', 'home_ownership', 'verification_status', 'issue_d', 'loan_status', 'pymnt_plan', 'purpose', 'title', 'zip_code', 'addr_state', 'earliest_cr_line', 'revol_util', 'initial_list_status', 'last_pymnt_d', 'last_credit_pull_d', 'application_type']\n"
     ]
    }
   ],
   "source": [
    "#Let's check the missmatching chunk's columns\n",
    "\n",
    "chunk_iter=pd.read_csv(\"loans_2007.csv\", chunksize=3000)\n",
    "\n",
    "obj_col=[]\n",
    "\n",
    "for chunk in chunk_iter:\n",
    "    obj_chunk=chunk.select_dtypes(include=['object']).columns.tolist()  #From the object dataframe, we took only the column names and made them into a list\n",
    "    \n",
    "    if len(obj_col) > 0:\n",
    "        if obj_col != obj_chunk:      #checking if there is any column missmatch \n",
    "            print(\"\\n\",\"all_colums:\",obj_col)\n",
    "            print(\"\\n\",\"chunk_object_columns:\",obj_chunk)\n",
    "    else:\n",
    "        obj_col=obj_chunk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm here that, in the last 2 chunks the column 'id' is being shown which is supposed to be numeric column. So 'id' column has both numeric and object data type. Since id column won't be that useful for analysis we can ignore this column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many unique values are there in each string column? How many of the string columns contain values that are less than 50% unique?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_values_in_each_column: {'term': 2, 'int_rate': 394, 'grade': 7, 'sub_grade': 35, 'emp_title': 30658, 'emp_length': 11, 'home_ownership': 5, 'verification_status': 3, 'issue_d': 55, 'loan_status': 9, 'pymnt_plan': 2, 'purpose': 14, 'title': 21264, 'zip_code': 837, 'addr_state': 50, 'earliest_cr_line': 530, 'revol_util': 1119, 'initial_list_status': 1, 'last_pymnt_d': 103, 'last_credit_pull_d': 108, 'application_type': 1, 'id': 3538}\n",
      "\n",
      " Columns with less than 50% unique values: {'term': 2, 'int_rate': 394, 'grade': 7, 'sub_grade': 35, 'emp_length': 11, 'home_ownership': 5, 'verification_status': 3, 'issue_d': 55, 'loan_status': 9, 'pymnt_plan': 2, 'purpose': 14, 'zip_code': 837, 'addr_state': 50, 'earliest_cr_line': 530, 'revol_util': 1119, 'initial_list_status': 1, 'last_pymnt_d': 103, 'last_credit_pull_d': 108, 'application_type': 1}\n",
      "\n",
      " Columns with less than 50 unique values: {'term': 2, 'grade': 7, 'sub_grade': 35, 'emp_length': 11, 'home_ownership': 5, 'verification_status': 3, 'loan_status': 9, 'pymnt_plan': 2, 'purpose': 14, 'initial_list_status': 1, 'application_type': 1}\n"
     ]
    }
   ],
   "source": [
    "chunk_iter=pd.read_csv(\"loans_2007.csv\", chunksize=3000)\n",
    "\n",
    "col_val_counts={}\n",
    "\n",
    "for chunk in chunk_iter:\n",
    "    obj_columns=chunk.select_dtypes(include=['object']).columns.tolist()  #We took the names of a columns into a list\n",
    "    for column in obj_columns:                                            #we used those column names to loop over dataframe  \n",
    "        val_count=chunk[column].value_counts()                            \n",
    "        if column in col_val_counts:\n",
    "            col_val_counts[column].append(val_count)\n",
    "        else:\n",
    "            col_val_counts[column]=[val_count]                         #We set the value as list. so that we can append the key(columns) data of other chunks\n",
    "\n",
    "unique_val_col={}\n",
    "\n",
    "less_50_percentage_unique={}\n",
    "\n",
    "less_50_unique_values={}          \n",
    "\n",
    "for col in col_val_counts:\n",
    "    u_concat=pd.concat(col_val_counts[col])             #The unique_val_counts dic has multiple chunks data. So we concat them into single series\n",
    "    u_group=u_concat.groupby(u_concat.index).sum()         #When we concat, we might get duplicates, therefore we group them and sum their value\n",
    "    unique_val_col[col]=len(u_group)\n",
    "    \n",
    "    if len(u_group) < 50:\n",
    "        less_50_unique_values[col]=len(u_group)\n",
    "    \n",
    "    total_val=u_concat.sum()\n",
    "    unique_percentage=(len(u_group)/total_val)*100\n",
    "    \n",
    "    if unique_percentage < 50:\n",
    "        less_50_percentage_unique[col]=(len(u_group))\n",
    "        \n",
    "\n",
    "print(\"unique_values_in_each_column:\",unique_val_col)\n",
    "\n",
    "print(\"\\n\",\"Columns with less than 50% unique values:\",less_50_percentage_unique)\n",
    "\n",
    "print(\"\\n\", \"Columns with less than 50 unique values:\", less_50_unique_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Since some columns in \"less_50_percentage_unique\" have high cardinality, we chose to focus on columns with \"less_50_unique_values\" as they have very low cardinality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which float columns have no missing values and could be candidates for conversion to the integer type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collection_recovery_fee          3\n",
       "dti                              3\n",
       "loan_amnt                        3\n",
       "member_id                        3\n",
       "last_pymnt_amnt                  3\n",
       "installment                      3\n",
       "funded_amnt_inv                  3\n",
       "funded_amnt                      3\n",
       "total_pymnt                      3\n",
       "total_pymnt_inv                  3\n",
       "total_rec_int                    3\n",
       "revol_bal                        3\n",
       "recoveries                       3\n",
       "policy_code                      3\n",
       "out_prncp_inv                    3\n",
       "out_prncp                        3\n",
       "total_rec_prncp                  3\n",
       "total_rec_late_fee               3\n",
       "annual_inc                       7\n",
       "open_acc                        32\n",
       "delinq_amnt                     32\n",
       "delinq_2yrs                     32\n",
       "acc_now_delinq                  32\n",
       "inq_last_6mths                  32\n",
       "pub_rec                         32\n",
       "total_acc                       32\n",
       "tax_liens                      108\n",
       "collections_12_mths_ex_med     148\n",
       "chargeoff_within_12_mths       148\n",
       "pub_rec_bankruptcies          1368\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_iter=pd.read_csv(\"loans_2007.csv\", chunksize=3000)\n",
    "\n",
    "missing_counts=[]\n",
    "\n",
    "for chunk in chunk_iter:\n",
    "    float_chunk=chunk.select_dtypes(include=[\"float\"])\n",
    "    missing_counts.append(float_chunk.apply(pd.isnull).sum())    #apply.(pd.isnull) will Returns a DataFrame of the same shape as float_chunk, where each cell is True if the value is NaN and False otherwise. .sum() makes the column name as index and show the summed value\n",
    "    \n",
    "combined_missing=pd.concat(missing_counts)\n",
    "combined_missing.groupby(combined_missing.index).sum().sort_values()\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems there are no columns without missing values. However there are many columns with just 3 missing values which can be used for further optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the total memory usage across all chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.24251079559326\n"
     ]
    }
   ],
   "source": [
    "chunk_iter=pd.read_csv(\"loans_2007.csv\", chunksize=3000)\n",
    "\n",
    "initial_memory=0\n",
    "\n",
    "for chunk in chunk_iter:\n",
    "    memory=chunk.memory_usage(deep=True).sum()/(1024*1024)\n",
    "    initial_memory+=memory\n",
    "    \n",
    "print(initial_memory)  #Total memory that need to process the complete dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing String Columns & Calculate the total memory footprint and compare it with the previous one.\n",
    "\n",
    "Optimize the object columns by changing the data type of columns that has low cardinality into 'category' possible columns into numeric data type by cleaning them, changing the data columns into date type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'term': 2, 'grade': 7, 'sub_grade': 35, 'emp_length': 11, 'home_ownership': 5, 'verification_status': 3, 'loan_status': 9, 'pymnt_plan': 2, 'purpose': 14, 'initial_list_status': 1, 'application_type': 1}\n"
     ]
    }
   ],
   "source": [
    "print(less_50_unique_values) #Since we already found the less_50_unique_values we can use it to change into category & numeric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on our observation the columns 'term', 'int_rate', 'revol_util' are the potential columns that can be changed into numeric by doing some cleaning.\n",
    "\n",
    "numeric_col=['term', 'int_rate', 'revol_util'] #potential numeric columns. These columns can be changed into numeric by cleaning them\n",
    "\n",
    "category_dtype = {\n",
    "    'grade': 'category', \n",
    "    'sub_grade': 'category',\n",
    "    'emp_length': 'category',\n",
    "    'home_ownership': 'category',\n",
    "    'verification_status': 'category',\n",
    "    'loan_status': 'category',\n",
    "    'pymnt_plan': 'category',\n",
    "    'purpose': 'category',\n",
    "    'initial_list_status': 'category',\n",
    "    'application_type': 'category'\n",
    "}                                     #potential columns for category dtype which we will use while reading the chunks\n",
    "\n",
    "date_columns=['last_pymnt_d', 'last_credit_pull_d', 'issue_d'] #potential columns for date dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Memory before object dtype optimization: 65.24251079559326\n",
      "\n",
      " Memory after object dtype optimization 23.905481338500977\n"
     ]
    }
   ],
   "source": [
    "chunk_iter=pd.read_csv(\"loans_2007.csv\", chunksize=3000, dtype=category_dtype)\n",
    "\n",
    "\n",
    "date_columns = [\"issue_d\", \"earliest_cr_line\", \"last_pymnt_d\", \"last_credit_pull_d\"]\n",
    "date_format = \"%b-%Y\"\n",
    "\n",
    "\n",
    "processed_chunks=[]\n",
    "memory_aft_object_optimization=0\n",
    "\n",
    "for chunk in chunk_iter:\n",
    "    if 'term' in chunk.columns:\n",
    "        chunk['term']=chunk['term'].str.rstrip(' months').astype('float')\n",
    "    if 'int_rate' in chunk.columns:\n",
    "        chunk['int_rate']=chunk['int_rate'].str.rstrip('%').astype('float')\n",
    "    if 'revol_util' in chunk.columns:\n",
    "        chunk['revol_util']=chunk['revol_util'].str.rstrip('%').astype('float')\n",
    "    for col in date_columns:\n",
    "        if col in chunk.columns:\n",
    "            chunk[col] = pd.to_datetime(chunk[col], format=date_format)\n",
    "    \n",
    "    processed_chunks.append(chunk)\n",
    "    \n",
    "    memory=chunk.memory_usage(deep=True).sum()/(1024*1024)\n",
    "    memory_aft_object_optimization+=memory\n",
    "\n",
    "combined=pd.concat(processed_chunks)    #We are concating the output of all chunks together\n",
    "\n",
    "\n",
    "print(\" Memory before object dtype optimization:\", initial_memory)\n",
    "print(\"\\n\",\"Memory after object dtype optimization\",memory_aft_object_optimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing the numeric columns and calculate the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns and their missing values count: \n",
      " collection_recovery_fee          3\n",
      "dti                              3\n",
      "last_pymnt_amnt                  3\n",
      "loan_amnt                        3\n",
      "int_rate                         3\n",
      "installment                      3\n",
      "funded_amnt_inv                  3\n",
      "funded_amnt                      3\n",
      "member_id                        3\n",
      "total_rec_int                    3\n",
      "total_pymnt_inv                  3\n",
      "recoveries                       3\n",
      "revol_bal                        3\n",
      "policy_code                      3\n",
      "out_prncp_inv                    3\n",
      "out_prncp                        3\n",
      "total_rec_late_fee               3\n",
      "total_pymnt                      3\n",
      "term                             3\n",
      "total_rec_prncp                  3\n",
      "annual_inc                       7\n",
      "delinq_amnt                     32\n",
      "inq_last_6mths                  32\n",
      "acc_now_delinq                  32\n",
      "total_acc                       32\n",
      "pub_rec                         32\n",
      "open_acc                        32\n",
      "delinq_2yrs                     32\n",
      "revol_util                      93\n",
      "tax_liens                      108\n",
      "chargeoff_within_12_mths       148\n",
      "collections_12_mths_ex_med     148\n",
      "pub_rec_bankruptcies          1368\n",
      "dtype: int64\n",
      "\n",
      " Float columns with no missing values: Series([], dtype: int64)\n",
      "\n",
      " {'member_id': dtype('float64'), 'loan_amnt': dtype('float64'), 'funded_amnt': dtype('float64'), 'funded_amnt_inv': dtype('float64'), 'term': dtype('float64'), 'int_rate': dtype('float64'), 'installment': dtype('float64'), 'annual_inc': dtype('float64'), 'dti': dtype('float64'), 'delinq_2yrs': dtype('float64'), 'inq_last_6mths': dtype('float64'), 'open_acc': dtype('float64'), 'pub_rec': dtype('float64'), 'revol_bal': dtype('float64'), 'revol_util': dtype('float64'), 'total_acc': dtype('float64'), 'out_prncp': dtype('float64'), 'out_prncp_inv': dtype('float64'), 'total_pymnt': dtype('float64'), 'total_pymnt_inv': dtype('float64'), 'total_rec_prncp': dtype('float64'), 'total_rec_int': dtype('float64'), 'total_rec_late_fee': dtype('float64'), 'recoveries': dtype('float64'), 'collection_recovery_fee': dtype('float64'), 'last_pymnt_amnt': dtype('float64'), 'collections_12_mths_ex_med': dtype('float64'), 'policy_code': dtype('float64'), 'acc_now_delinq': dtype('float64'), 'chargeoff_within_12_mths': dtype('float64'), 'delinq_amnt': dtype('float64'), 'pub_rec_bankruptcies': dtype('float64'), 'tax_liens': dtype('float64')}\n",
      "\n",
      " Memory before numeric dtype optimization: 65.24251079559326\n",
      "\n",
      " Memory after numeric dtype optimization: 19.634538650512695\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chunk_iter = pd.read_csv(\"loans_2007.csv\", chunksize=3000, dtype=category_dtype)\n",
    "\n",
    "date_columns = [\"issue_d\", \"earliest_cr_line\", \"last_pymnt_d\", \"last_credit_pull_d\"]\n",
    "date_format = \"%b-%Y\"\n",
    "\n",
    "memory_aft_optimization=0\n",
    "missing_counts = []  #Columns with missing values\n",
    "float_dtypes = {}  #The exact dtypes of of the float columns\n",
    "\n",
    "for chunk in chunk_iter:\n",
    "    if 'term' in chunk.columns:\n",
    "        chunk['term']=chunk['term'].str.rstrip(' months').astype('float')\n",
    "    if 'int_rate' in chunk.columns:\n",
    "        chunk['int_rate']=chunk['int_rate'].str.rstrip('%').astype('float')\n",
    "    if 'revol_util' in chunk.columns:\n",
    "        chunk['revol_util']=chunk['revol_util'].str.rstrip('%').astype('float')\n",
    "    for col in date_columns:\n",
    "        if col in chunk.columns:\n",
    "            chunk[col] = pd.to_datetime(chunk[col], format=date_format)\n",
    "       \n",
    "    float_chunk = chunk.select_dtypes(include=[\"float\"])   #Filtered columns with float type\n",
    "        \n",
    "    missing_counts.append(float_chunk.isnull().sum())     \n",
    "    \n",
    "    for col in float_chunk.columns:\n",
    "        if col not in float_dtypes:\n",
    "            float_dtypes[col] = float_chunk[col].dtype\n",
    "        if float_chunk[col].dtype=='float64':    #We check the the dtype=='float64' and also if there is any missing values\n",
    "            chunk[col] = pd.to_numeric(chunk[col], downcast='float')\n",
    "    \n",
    "    memory=chunk.memory_usage(deep=True).sum()/(1024*1024)\n",
    "    memory_aft_optimization+=memory   \n",
    "\n",
    "combined_missing = pd.concat(missing_counts)   #combining each chunk's results together\n",
    "\n",
    "missing_values_summary = combined_missing.groupby(combined_missing.index).sum().sort_values()\n",
    "\n",
    "No_missing_float_cols = missing_values_summary[missing_values_summary == 0 ]  #Filitering columns with only missing values to identify what columns we can change to int dtype\n",
    " \n",
    "        \n",
    "print(\"Columns and their missing values count:\", \"\\n\",missing_values_summary)\n",
    "\n",
    "print(\"\\n\", \"Float columns with no missing values:\",No_missing_float_cols)      #let's checking columns missing value counts\n",
    "\n",
    "print(\"\\n\", float_dtypes)               #Checking float columns actual datatype\n",
    "\n",
    "print(\"\\n\", \"Memory before numeric dtype optimization:\", initial_memory)\n",
    "print(\"\\n\",\"Memory after numeric dtype optimization:\", memory_aft_optimization)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "1. We found no potential float columns that can be converted into integer since there were no columns with zero missing value\n",
    "2. All the float columns were in float64 and many of them had missing values since we don't need much precision here we downcast them to optimize further\n",
    "3. After downcasting and full optimization we were able to reduce the size down to 19 MB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conculsion\n",
    "\n",
    "By using chunk processing, optimizing data types (especially strings to categories and downcasting floats), parsing dates, and handling missing values, a substantial reduction in memory usage can be achieved for the \"loans_2007.csv\" dataset. This makes it more efficient to process the data, especially when dealing with large datasets."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
